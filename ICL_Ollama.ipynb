{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb682432",
   "metadata": {},
   "source": [
    "# Metaphor Detection via In Context Learning with Local Model in Ollama\n",
    "\n",
    "In this notebook, I will show the workflow of metaphor detection via in context learning(ICL) with local model. Here, we host local model in Ollama.\n",
    "\n",
    "Let's start with the dependencies. To run this notebook, you need the following packages: ollama, pandas.\n",
    "\n",
    "Run the following script to install these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a5d5e",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef6b12",
   "metadata": {},
   "source": [
    "Next, you'll need to load the prompt(s). The prompt(s) are stored as csv. You can use the following script to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_fp=\"prompt/prompt_cot.csv\"\n",
    "prompt_df=pd.read_csv(prompt_fp,index_col=0)\n",
    "pids=list(set(prompt_df.index.to_list()))\n",
    "p_strats={}\n",
    "p_strats_info={}\n",
    "for pid in pids:\n",
    "    chat_temp_df=prompt_df.loc[pid]\n",
    "    chat_temp=[]\n",
    "    for i in range(0,chat_temp_df.shape[0]):\n",
    "        item=chat_temp_df.iloc[i]\n",
    "        chat_temp.append({\"role\":item[\"role\"],\"content\":item[\"content\"]})\n",
    "    p_strats[pid]=chat_temp\n",
    "    p_strats_info[pid]=chat_temp_df.iloc[0][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38e488",
   "metadata": {},
   "source": [
    "The prompts are stored in the dictionary p_strats. You may access prompt via prompt_id(pid). For a full list of pid:prompt strategy, simply check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2095e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: 'V2a. Chain-of-thought, 4 shots, Original conventional vs creative ratio',\n",
       " 101: 'V2b. Chain-of-thought, 4 shots, Even conventional vs creative ratio',\n",
       " 102: 'V2c. Chain-of-thought, 8 shots, Original conventional vs creative ratio',\n",
       " 103: 'V2d. Chain-of-thought, 8 shots, Even conventional vs creative ratio',\n",
       " 104: 'V6a. Chain-of-thought, 4 shots, Original conventional vs creative ratio',\n",
       " 105: 'V6b. Chain-of-thought, 4 shots, Even conventional vs creative ratio',\n",
       " 106: 'V6c. Chain-of-thought, 8 shots, Original conventional vs creative ratio',\n",
       " 107: 'V6d. Chain-of-thought, 8 shots, Even conventional vs creative ratio',\n",
       " 108: 'V7a. Chain-of-thought, 4 shots, Original conventional vs creative ratio',\n",
       " 109: 'V7b. Chain-of-thought, 4 shots, Even conventional vs creative ratio',\n",
       " 110: 'V7c. Chain-of-thought, 8 shots, Original conventional vs creative ratio',\n",
       " 111: 'V7d. Chain-of-thought, 8 shots, Even conventional vs creative ratio'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_strats_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a2e29",
   "metadata": {},
   "source": [
    "Select your prompt strategy via prompt id using the folllowing script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_strat=p_strats[pid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5297cc",
   "metadata": {},
   "source": [
    "After the prompts are loaded, you'll need to load the test text. To load it from our corpus, simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fp=\"data/metaphor_dataset.csv\"\n",
    "ds_df=pd.read_csv(ds_fp,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4f27b",
   "metadata": {},
   "source": [
    "You may input your own test text in the following script. Or, alternatively, you may choose a sample test text from our corpus, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23256f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \" something is fishy in the state of universal . \" \n",
      "\n",
      "about ten years back , with the unexpected success of mad max and the road warrior , post-apocalypse nitty-gritty survival yarns became popular at the movies . \n",
      "\n",
      "we've always had movies of this nature ; on the beach , the end of the world , damnation alley , the ultimate warrior , and so on . \n",
      "\n",
      "to date , the most smoothly done were straightforward \" haircuts \" of the classic western plot , like the lone gunman who comes to town and protects the widow and the son against an evil organization , usually one in possession of some critical resource , like water , feed range , or a mining claim . \n",
      "\n",
      "most of these grew out of venerable , but solid hero yarns like the virginian and shane . \n",
      "\n",
      " ( my personal favorite is a patrick swayze movie called steel dawn , which was fairly well made on a small budget . ) \n",
      "\n",
      "now we have waterworld , which again brings the traditional lone gunman to town to rescue the young widow and her daughter . \n",
      "\n",
      " ( well , she's not a widow , and the kid isn't her daughter , but you get the idea . ) \n",
      "\n",
      "the lady is helen , played by the stunning jean tripplehorn , who isn't given a chance to be stunning , or even interesting , by the mediocre and unimaginative script . \n",
      "\n",
      "the child enola , played by tina majorino , is living proof that a child actor need not be a bad thing to have in a movie ; she outshines her material all the way through . \n",
      "\n",
      "in simple , the scene is earth , hundreds of years from now . \n",
      "\n",
      "the polar ice caps have melted , and somehow produced enough water to inundate the entire planet . \n",
      "\n",
      "the few remaining people live in boats and floating colonies , and survive by trade , theft , or piracy . \n",
      "\n",
      "somehow an oil tanker has survived the centuries , and its inhabitants , called \" smokers , \" are able to keep gasoline engines running despite the dearth of replacement parts and raw materials , so the bad guys have outboard engines , and fast-moving boats , airplanes , and jet skis . \n",
      "\n",
      "enola , found at sea as a young girl , has a mysterious map no one can read tattooed on her back . \n",
      "\n",
      "we suspect early on that it is the way to the mythical \" dryland , \" the place where trees , crops , and animals grow , and what plot there is hinges on who has enola . \n",
      "\n",
      "the psycho ruler of the smokers , the \" deacon , \" is trying to get her and find his way to dryland . \n",
      "\n",
      "played with typical self-lampooning , rug-chewing histrionics by dennis hopper , \" deacon \" is the only thing in the movie that's close to amusing . \n",
      "\n",
      "his performance is * almost * laughable , but there just isn't enough there to be funny . \n",
      "\n",
      "the star ( and a co-producer ) is kevin costner . \n",
      "\n",
      "he's playing an un-named lone denizen of the sea , a man called the \" mariner , \" who turns out to be a gilled , water-breathing mutant with webbed feet . \n",
      "\n",
      "very little is done with this . \n",
      "\n",
      "the script ignores the ineffectuality of gills in supplying enough oxygen to support a human metabolism ; it ignores the fact that even with both ice caps completely melted , much of the earth's surface would still be above water ; and it ignores the blatant impossibility of the cultures and technology shown . \n",
      "\n",
      " ( canned meat does * not * last for centuries ; ammunition does * not * fire after it's more than a few decades old ; and so on , and so on . . . ) \n",
      "\n",
      "i'm quite fond of tina majorino's previous work , very impressed by jean tripplehorn's past accomplishments , and still speechless over costner's dances with wolves . \n",
      "\n",
      "but this movie could destroy the careers of anyone associated with it ! \n",
      "\n",
      "this movie cost one hundred and eighty-two million dollars , and there's * nothing * in it we haven't seen before , done better on only a few percent of the cost of this turkey . \n",
      "\n",
      "at 125 minutes of material , this movie cost over one point four million dollars per minute to make . \n",
      "\n",
      "the budget of this movie * could * have given us over thirty movies ; it could have paid for six years of a prime-time sf tv series with expensive fx work , or ten years of an sf tv series with good digital fx . \n",
      "\n",
      "in sum , this movie is beneath contempt . \n",
      "\n",
      "it has nothing new to offer , it has a script that could easily have been bettered by the people who write comic books for dc , and it spent more money than the national budget of a small nation . \n",
      "\n",
      "if you * have * to go see it , see it on a four-dollar matinee . \n",
      "\n",
      "otherwise you'll find yourself sneering at you every time you pass a reflective surface , for weeks . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_text=ds_df.iloc[0][\"plain\"]\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5192c92",
   "metadata": {},
   "source": [
    "Next, as the last step required before run, you need to specify a model.\n",
    "\n",
    "The models we used in our paper are:\n",
    "\n",
    "llama3.2:1b\n",
    "\n",
    "llama3.2:3b\n",
    "\n",
    "llama3.1:8b\n",
    "\n",
    "deepseek-r1:8b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a15c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583fedb8",
   "metadata": {},
   "source": [
    "Note: to use the model you specify, you'll need ollama installed and started. You may download Ollama here:\n",
    "\n",
    "https://ollama.com/\n",
    "\n",
    "And if ollama is not started, simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8809ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7aeed1",
   "metadata": {},
   "source": [
    "Also, if you haven't download the model you specified, you may use the following script to download the model.\n",
    "\n",
    "(Here I use llama3.2:1b as an example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ee29e",
   "metadata": {},
   "source": [
    "Pack the chat of the sample text under prompt strategy, send chat to model for inferring, and retrieve result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_strat=p_strats[pid]\n",
    "ct=copy.deepcopy(p_strat)\n",
    "ct[-1][\"content\"]=ct[-1][\"content\"].replace(\"[#TEST_TEXT]\",test_text)\n",
    "cr=chat(model=modelid, messages=ct)\n",
    "rs=cr.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771d1fe",
   "metadata": {},
   "source": [
    "View the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1803636",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
