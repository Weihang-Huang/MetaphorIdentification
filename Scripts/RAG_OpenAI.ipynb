{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d753080e",
   "metadata": {},
   "source": [
    "# Metaphor Identification via RAG with OpenAI Model\n",
    "\n",
    "This notebook details the process of metaphor identification via RAG using the OpenAI Model.\n",
    "\n",
    "The following packages are needed to run this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177af60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d782f6",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c29574",
   "metadata": {},
   "source": [
    "Please input a test text here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7463087",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_text=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db09b7",
   "metadata": {},
   "source": [
    "Or, alternatively, you may choose a test text from our metaphor corpus.\n",
    "\n",
    "(Here, we choose the first text as an example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fp=\"data/metaphor_dataset.csv\"\n",
    "ds_df=pd.read_csv(ds_fp)\n",
    "ds_df=ds_df[[\"textid\",\"plain\"]]\n",
    "ds_df.rename(columns={\"plain\":\"context\"},inplace=True)\n",
    "\n",
    "key_text=ds_df.loc[0,\"context\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267a61a",
   "metadata": {},
   "source": [
    "Load the metaphor protocol in plain text. This is used as the knowledge base for context retrival in the following process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_context_fp=\"data/rag_context.txt\"\n",
    "with open(total_context_fp,\"r\",-1) as f:\n",
    "    total_context=f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671949a",
   "metadata": {},
   "source": [
    "Transform the text into Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7902045",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[[Document(page_content=text)] for text in [total_context]]\n",
    "docs_list=[item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df4d87",
   "metadata": {},
   "source": [
    "Split documents into chunks, on which the retrival is based upon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090486ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0)\n",
    "doc_splits=text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f7025",
   "metadata": {},
   "source": [
    "Vectorizing the split documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7072af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa4a18",
   "metadata": {},
   "source": [
    "Construct a retriever, and use it to retrieve the context based on the inputted test text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever(k=1)\n",
    "retrieved_documents=retriever.invoke(key_text)\n",
    "context=retrieved_documents[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aadbb71",
   "metadata": {},
   "source": [
    "Construct the chat based on the retrieved context and the test text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e440f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_strat=[\n",
    "    {\"role\":\"system\",\n",
    "     \"content\":\"You are a helpful AI assistant. Use the following pieces of context to answer the question at the end. If you don't know the answer, just say you don't know. DO NOT try to make up an answer. If the question is not related to the context, politely respond that you are tuned to only answer questions that are related to the context.\\n\"},\n",
    "    {'role': 'system',\n",
    "    'content': 'You are a linguistic expert trained in metaphor identification. When the user provides a text, follow this protocol:\\n• Identify all metaphorical expressions.\\n• Wrap each one in <Metaphor> and </Metaphor> tags.\\n• Reproduce the rest of the text exactly as written.\\n• Do not include any explanation, commentary, or extra content in this message.'},\n",
    "    {'role': 'user',\n",
    "    'content': 'Can you please identify and tag the metaphors in the following text?\\n'},\n",
    "]\n",
    "ct=p_strat.copy()\n",
    "p_strat[0][\"content\"]=p_strat[0][\"content\"]+context\n",
    "p_strat[-1][\"content\"]=p_strat[-1][\"content\"]+key_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d9877",
   "metadata": {},
   "source": [
    "You will also need to apply for an OpenAI api key to use models from OpenAI. \n",
    "\n",
    "After successful application, you'll need to put your API key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813795e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key=\"INSERT YOUR KEY HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d8c1c",
   "metadata": {},
   "source": [
    "With API key, you can connect to the openai server via the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41004f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016879a1",
   "metadata": {},
   "source": [
    "Next, as the last step required before run, you need to specify a model.\n",
    "\n",
    "The models we used in our paper are:\n",
    "\n",
    "gpt-4.1-mini-2025-04-14\n",
    "\n",
    "gpt-4.1-nano-2025-04-14\n",
    "\n",
    "gpt-4.1-2025-04-14\n",
    "\n",
    "o3-2025-04-16\n",
    "\n",
    "o4-mini-2025-04-16\n",
    "\n",
    "o3-mini-2025-01-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid=\"gpt-4.1-mini-2025-04-14\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818729ea",
   "metadata": {},
   "source": [
    "Send chat to model for inferring, and retrieve result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a589d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=client.chat.completions.create(model=modelid,messages=ct,n=1)# choose n>1 when you need to batch testing.\n",
    "\n",
    "rs=cr.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2643d15",
   "metadata": {},
   "source": [
    "View the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
