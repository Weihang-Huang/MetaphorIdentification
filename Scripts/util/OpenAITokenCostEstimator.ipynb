{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1144dbb1",
   "metadata": {},
   "source": [
    "# Token Usage & Cost Estimator — OpenAI Models\n",
    "\n",
    "This notebook helps you estimate token usage and **approximate** API costs for several OpenAI models based on a **test input text** that you provide.  \n",
    "It computes an estimated token count for your text and multiplies by the current per‑million token rates for each model.\n",
    "\n",
    "### Models covered\n",
    "- `gpt-4.1-2025-04-14`\n",
    "- `gpt-4.1-mini-2025-04-14`\n",
    "- `gpt-4.1-nano-2025-04-14`\n",
    "- `o3-2025-04-16`\n",
    "- `o4-mini-2025-04-16`\n",
    "- `o3-mini-2025-01-31`\n",
    "\n",
    "### What you’ll get\n",
    "- Estimated input token count for your test text\n",
    "- Optional assumed output tokens (defaults to 25% of input)\n",
    "- Estimated cost (USD) per model for input + output tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee639e3",
   "metadata": {},
   "source": [
    "\n",
    "## Pricing sources (as of Sep 2025)\n",
    "The per‑million token prices below are taken from OpenAI's official docs/pages (as of late 2025):\n",
    "\n",
    "- **GPT‑4.1**: $2.00 input / $0.50 cached input / $8.00 output per 1M tokens.  \n",
    "- **GPT‑4.1 mini**: $0.40 input / $0.10 cached input / $1.60 output per 1M tokens.  \n",
    "- **GPT‑4.1 nano**: $0.10 input / $0.025 cached input / $0.40 output per 1M tokens.  \n",
    "- **o3** (reasoning): $2.00 input / $0.50 cached input / $8.00 output per 1M tokens.  \n",
    "- **o4‑mini** (reasoning): $2.00 input / $0.50 cached input / $8.00 output per 1M tokens.  \n",
    "- **o3‑mini** (reasoning): $1.10 input / $0.55 cached input / $4.40 output per 1M tokens.\n",
    "\n",
    "Notes\n",
    "- “Cached input” rates apply when using prompt caching features.\n",
    "- Only text token rates are considered here.\n",
    "- Prices can change; always verify against the official pricing page before budgeting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654bc9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pricing for 6 models.\n"
     ]
    }
   ],
   "source": [
    "# === Configuration: model pricing (USD per 1M tokens) ===\n",
    "MODEL_PRICES = {\n",
    "    \"gpt-4.1-2025-04-14\":    {\"input_per_m\": 2.00,  \"cached_input_per_m\": 0.50,  \"output_per_m\": 8.00},\n",
    "    \"gpt-4.1-mini-2025-04-14\": {\"input_per_m\": 0.40,  \"cached_input_per_m\": 0.10,  \"output_per_m\": 1.60},\n",
    "    \"gpt-4.1-nano-2025-04-14\": {\"input_per_m\": 0.10,  \"cached_input_per_m\": 0.025, \"output_per_m\": 0.40},\n",
    "    \"o3-2025-04-16\":         {\"input_per_m\": 2.00,  \"cached_input_per_m\": 0.50,  \"output_per_m\": 8.00},\n",
    "    \"o4-mini-2025-04-16\":    {\"input_per_m\": 2.00,  \"cached_input_per_m\": 0.50,  \"output_per_m\": 8.00},\n",
    "    \"o3-mini-2025-01-31\":    {\"input_per_m\": 1.10,  \"cached_input_per_m\": 0.55,  \"output_per_m\": 4.40},\n",
    "}\n",
    "\n",
    "MODEL_LIST = list(MODEL_PRICES.keys())\n",
    "\n",
    "print(f\"Loaded pricing for {len(MODEL_LIST)} models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42a8c7",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Paste your test text\n",
    "Change the `TEST_TEXT` variable below to your own text. This notebook will compute token estimates and costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a82456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your test text here. You can include multiple paragraphs, code, etc.\n",
      "The notebook will estimate tokens and compute costs for each model listed above.\n"
     ]
    }
   ],
   "source": [
    "TEST_TEXT = \"\"\"Paste your test text here. You can include multiple paragraphs, code, etc.\n",
    "The notebook will estimate tokens and compute costs for each model listed above.\"\"\"\n",
    "\n",
    "print(TEST_TEXT[:200] + (\"...\" if len(TEST_TEXT) > 200 else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba987fa",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Token counting\n",
    "We try to use the official `tiktoken` tokenizer if available locally.  \n",
    "If it's not available, we fall back to a heuristic:\n",
    "- **Heuristic estimate**: `ceil(len(text) / 4)` tokens (≈ 4 characters per token for English)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44510c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated input tokens: 30 (using tiktoken (o200k_base))\n"
     ]
    }
   ],
   "source": [
    "# === Token counting helpers ===\n",
    "import math\n",
    "\n",
    "def estimate_tokens_heuristic(text: str) -> int:\n",
    "    # Approximate: ~4 characters per token\n",
    "    return int(math.ceil(len(text) / 4)) if text else 0\n",
    "\n",
    "# Attempt to use tiktoken if available (optional)\n",
    "def count_tokens(text: str) -> tuple[int, str]:\n",
    "    \"\"\"Return (token_count, method_used).\"\"\"\n",
    "    try:\n",
    "        import tiktoken  # requires local install\n",
    "        # Use a modern tokenizer as a reasonable default. Fall back to cl100k_base if o200k_base is unavailable.\n",
    "        try:\n",
    "            enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "        except Exception:\n",
    "            enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens = enc.encode(text)\n",
    "        return len(tokens), f\"tiktoken ({enc.name})\"\n",
    "    except Exception:\n",
    "        return estimate_tokens_heuristic(text), \"heuristic (~4 chars ≈ 1 token)\"\n",
    "\n",
    "INPUT_TOKENS, TOKENIZER_USED = count_tokens(TEST_TEXT)\n",
    "print(f\"Estimated input tokens: {INPUT_TOKENS} (using {TOKENIZER_USED})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e8599",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Set an assumed output length (optional)\n",
    "Set `ASSUMED_OUTPUT_TOKENS` if you already know roughly how long the model's response will be.  \n",
    "Otherwise, we’ll default to `OUTPUT_TO_INPUT_RATIO = 0.25` (i.e., 25% as many output tokens as input).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf010b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumed output tokens: 8\n"
     ]
    }
   ],
   "source": [
    "ASSUMED_OUTPUT_TOKENS=None   # e.g., set to an integer like 150, or leave as None to use the ratio\n",
    "OUTPUT_TO_INPUT_RATIO=0.25   # used only when ASSUMED_OUTPUT_TOKENS is None\n",
    "\n",
    "OUTPUT_TOKENS = ASSUMED_OUTPUT_TOKENS if ASSUMED_OUTPUT_TOKENS is not None else int(math.ceil(INPUT_TOKENS * OUTPUT_TO_INPUT_RATIO))\n",
    "print(f\"Assumed output tokens: {OUTPUT_TOKENS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cda109",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Compute costs\n",
    "Costs are linear in tokens:\n",
    "- **Input cost** = `input_tokens / 1e6 * input_price_per_million`\n",
    "- **Output cost** = `output_tokens / 1e6 * output_price_per_million`\n",
    "We compute both **standard** and **cached** input scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74dcb34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  input_tokens  output_tokens  used_cached_input  \\\n",
      "0  gpt-4.1-nano-2025-04-14            30              8              False   \n",
      "1  gpt-4.1-mini-2025-04-14            30              8              False   \n",
      "2       o3-mini-2025-01-31            30              8              False   \n",
      "3       gpt-4.1-2025-04-14            30              8              False   \n",
      "4            o3-2025-04-16            30              8              False   \n",
      "5       o4-mini-2025-04-16            30              8              False   \n",
      "\n",
      "   input_cost_usd  output_cost_usd  total_cost_usd  \n",
      "0        0.000003         0.000003        0.000006  \n",
      "1        0.000012         0.000013        0.000025  \n",
      "2        0.000033         0.000035        0.000068  \n",
      "3        0.000060         0.000064        0.000124  \n",
      "4        0.000060         0.000064        0.000124  \n",
      "5        0.000060         0.000064        0.000124  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cost_breakdown(model_name: str, in_tokens: int, out_tokens: int, use_cached: bool = False) -> dict:\n",
    "    p = MODEL_PRICES[model_name]\n",
    "    in_rate = p[\"cached_input_per_m\"] if use_cached else p[\"input_per_m\"]\n",
    "    out_rate = p[\"output_per_m\"]\n",
    "    in_cost = (in_tokens / 1_000_000) * in_rate\n",
    "    out_cost = (out_tokens / 1_000_000) * out_rate\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"input_tokens\": in_tokens,\n",
    "        \"output_tokens\": out_tokens,\n",
    "        \"used_cached_input\": use_cached,\n",
    "        \"input_cost_usd\": round(in_cost, 6),\n",
    "        \"output_cost_usd\": round(out_cost, 6),\n",
    "        \"total_cost_usd\": round(in_cost + out_cost, 6),\n",
    "    }\n",
    "\n",
    "rows_standard = [cost_breakdown(m, INPUT_TOKENS, OUTPUT_TOKENS, use_cached=False) for m in MODEL_LIST]\n",
    "\n",
    "\n",
    "df_standard=pd.DataFrame(rows_standard).sort_values(\"total_cost_usd\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df_standard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
